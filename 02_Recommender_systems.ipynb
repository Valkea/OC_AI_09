{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93abafbe-0ac7-40b0-ade8-96c53aab4356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valkea/Dev/OpenClassrooms/Projets_AI/P9/venvP9/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import implicit\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit import evaluation\n",
    "\n",
    "import ml_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad39195-a13c-4fef-b6db-357ba86c628d",
   "metadata": {},
   "source": [
    "### Chargeons les jeux de données `training` et `validation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da144555-b437-4d9f-b42d-60de186a8588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>234853</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>159359</td>\n",
       "      <td>0.215827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>154</td>\n",
       "      <td>96663</td>\n",
       "      <td>0.145631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id     score\n",
       "0       59      234853  0.214286\n",
       "1       79      159359  0.215827\n",
       "2      154       96663  0.145631"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1577295, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train = pd.read_csv('data/data_train.csv')\n",
    "display(data_train.head(3), data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44a3e34b-21f9-4a36-b5fb-e5542943278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279777</td>\n",
       "      <td>96210</td>\n",
       "      <td>0.109489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29634</td>\n",
       "      <td>284773</td>\n",
       "      <td>0.469863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>162605</td>\n",
       "      <td>1.324273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id     score\n",
       "0   279777       96210  0.109489\n",
       "1    29634      284773  0.469863\n",
       "2       55      162605  1.324273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(241105, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_valid = pd.read_csv('data/data_valid.csv')\n",
    "display(data_valid.head(3), data_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cac9e4-95f4-47c1-a3b9-a5bdf0de5b7e",
   "metadata": {},
   "source": [
    "### Chargons les embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede8ce6e-3345-4a28-8d28-b0921f0bb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/news-portal-user-interactions-by-globocom/articles_embeddings.pickle',\"rb\")\n",
    "article_embedding = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a882fa2-99bc-4093-b048-f23687abf86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.16118301, -0.95723313, -0.13794445, ..., -0.231686  ,\n",
       "         0.5974159 ,  0.40962312],\n",
       "       [-0.52321565, -0.974058  ,  0.73860806, ...,  0.18282819,\n",
       "         0.39708954, -0.83436364],\n",
       "       [-0.61961854, -0.9729604 , -0.20736018, ..., -0.44758022,\n",
       "         0.8059317 , -0.28528407],\n",
       "       [-0.7408434 , -0.97574896,  0.39169782, ..., -0.5378381 ,\n",
       "         0.24354108, -0.8853287 ],\n",
       "       [-0.2790515 , -0.97231525,  0.68537366, ..., -0.42406067,\n",
       "         0.18548405, -0.5802922 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(364047, 250)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(article_embedding[:5], article_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac00460b-6aa7-4645-8bed-19740e6f9d21",
   "metadata": {},
   "source": [
    "# 1. Candidate generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5b93a-6fe0-49ea-84a8-df68be85face",
   "metadata": {},
   "source": [
    "# 1.1 Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91970ea-b255-476b-baa8-a6848a5c9db2",
   "metadata": {},
   "source": [
    "### Préparons une sparse matrix pour entrainer nos algorithmes de collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308c5a47-bca5-446e-882c-dac681c6f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297141, 28002)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84041, 7576)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Train ---\n",
    "data_train['user_cat_code'] = data_train['user_id'].astype('category').cat.codes\n",
    "data_train['article_cat_code'] = data_train['article_id'].astype('category').cat.codes\n",
    "\n",
    "# train_sparse_item_user = sparse.csr_matrix((data_train['score'].astype(float), (data_train['article_cat_code'], data_train['user_cat_code'])))\n",
    "train_sparse_user_item = sparse.csr_matrix((data_train['score'].astype(float), (data_train['user_cat_code'], data_train['article_cat_code'])))\n",
    "display(train_sparse_user_item.shape)\n",
    "\n",
    "# --- Validation ---\n",
    "data_valid['user_cat_code'] = data_valid['user_id'].astype('category').cat.codes\n",
    "data_valid['article_cat_code'] = data_valid['article_id'].astype('category').cat.codes\n",
    "\n",
    "# valid_sparse_item_user = sparse.csr_matrix((data_valid['score'].astype(float), (data_valid['article_cat_code'], data_valid['user_cat_code'])))\n",
    "valid_sparse_user_item = sparse.csr_matrix((data_valid['score'].astype(float), (data_valid['user_cat_code'], data_valid['article_cat_code'])))\n",
    "\n",
    "display(valid_sparse_user_item.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77108fa9-5c0e-4999-a4d7-659c825c2db8",
   "metadata": {},
   "source": [
    "sparse_user_item.eliminate_zeros()\n",
    "sparse_user_item.data = np.ones(len(sparse_user_item.data))\n",
    "display(sparse_user_item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbd670-c24e-42b7-856a-1e77bcaf4d6c",
   "metadata": {},
   "source": [
    "### Utilisons un système permettant de rééquilibrer les notes implicites *(pour éviter de donner trop d'importance aux articles qui ont un très gros ratio `temps de lecture` / `nombre de mots`)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f89018-ccf8-4885-9bd4-c0bcc826e733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297141, 28002)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84041, 7576)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_sparse_item_user_bm25 = bm25_weight(sparse_item_user, K1=100, B=0.9).tocsr()\n",
    "train_sparse_user_item_bm25 = bm25_weight(train_sparse_user_item, K1=100, B=0.9).tocsr() # Implicit veut des matrices [user x item]\n",
    "valid_sparse_user_item_bm25 = bm25_weight(valid_sparse_user_item, K1=100, B=0.9).tocsr() # Implicit veut des matrices [user x item]\n",
    "\n",
    "display(train_sparse_user_item_bm25.shape)\n",
    "display(valid_sparse_user_item_bm25.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023be47-84a1-434c-8352-b708c38bd2c8",
   "metadata": {},
   "source": [
    "### Entrainons un premier modèle pour calculer les embeddings utilisateurs et faire des recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5954c15b-a174-4d0f-b992-6bb1b42c4869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:20<00:00,  5.21s/it]\n"
     ]
    }
   ],
   "source": [
    "model_bm25 = implicit.als.AlternatingLeastSquares(\n",
    "    factors=32, \n",
    "    regularization=0.05, \n",
    "    iterations=50,\n",
    "    alpha=40\n",
    ")\n",
    "\n",
    "model_bm25.fit(train_sparse_user_item_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16ab0b-60e6-4490-8394-04ef968b4767",
   "metadata": {},
   "source": [
    "### Testons une `recommandation sur la base d'un ou plusieurs utilisateurs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787ff9cf-1733-403f-9651-73434567581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Liste d'articles candidats pour l'utilisateur 59 --- \n",
      "\n",
      "catCode:      10394 \t article_id:     119592 \t score: 1.07\n",
      "catCode:       5718 \t article_id:      68866 \t score: 0.99\n",
      "catCode:       9556 \t article_id:     108854 \t score: 0.96\n",
      "catCode:       8217 \t article_id:      96663 \t score: 0.93\n",
      "catCode:      13935 \t article_id:     168868 \t score: 0.92\n",
      "\n",
      " --- Liste d'articles candidats pour l'utilisateur 1024 --- \n",
      "\n",
      "catCode:       8129 \t article_id:      96210 \t score: 1.33\n",
      "catCode:      26190 \t article_id:     336245 \t score: 1.28\n",
      "catCode:       1430 \t article_id:      20691 \t score: 1.18\n",
      "catCode:      14884 \t article_id:     183176 \t score: 1.17\n",
      "catCode:      18548 \t article_id:     233688 \t score: 1.06\n"
     ]
    }
   ],
   "source": [
    "# Make recommendations for the first 10 users in the dataset\n",
    "userids = [59, 1024] # liste d'ID utilisateurs\n",
    "rec_size = 5\n",
    "\n",
    "codes, scores = model_bm25.recommend(userids, valid_sparse_user_item_bm25[userids], N=rec_size, filter_already_liked_items=True) \n",
    "\n",
    "for i, user_id in enumerate(userids):\n",
    "    print(f\"\\n --- Liste d'articles candidats pour l'utilisateur {user_id} --- \\n\")\n",
    "    \n",
    "    for code, score in zip(codes[i], scores[i]):\n",
    "        idx = data_train[data_train.article_cat_code==code]['article_id'].iloc[0]\n",
    "        print(f\"catCode: {code:10} \\t article_id: {idx:10} \\t score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb4f59-700b-4235-a1d4-8ebd761e2a64",
   "metadata": {},
   "source": [
    "### Testons une `recommandation sur la base d'un article` *(ce n'est pas le but d'un Collaborative Filtering, mais on peut le faire alors autant l'essayer)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53bdf732-546e-45d7-8e1a-91125f59a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --- Liste d'articles candidats sur la base de l'article 162605 --- \n",
      "\n",
      "catCode:       6359 \t article_id:      74112 \t score: 0.96\n",
      "catCode:       3766 \t article_id:      47888 \t score: 0.81\n",
      "catCode:      22526 \t article_id:     285045 \t score: 0.80\n",
      "catCode:      13314 \t article_id:     162107 \t score: 0.80\n",
      "catCode:      16610 \t article_id:     206429 \t score: 0.79\n"
     ]
    }
   ],
   "source": [
    "article_id = 162605\n",
    "article_code = data_train[data_train.article_id == article_id]['article_cat_code'].iloc[0]\n",
    "rec_size = 5\n",
    "\n",
    "# Get similar items.\n",
    "codes, scores = model_bm25.similar_items(article_code, N=rec_size , filter_items=[article_code])\n",
    "\n",
    "print(f\"\\n --- Liste d'articles candidats sur la base de l'article {article_id} --- \\n\")\n",
    "for code, score in zip(codes, scores):\n",
    "    idx = data_train[data_train.article_cat_code==code]['article_id'].iloc[0]\n",
    "    print(f\"catCode: {code:10} \\t article_id: {idx:10} \\t score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc71569-2104-407d-b66e-dd085bb0ec66",
   "metadata": {},
   "source": [
    "### Evaluons le modèle\n",
    "\n",
    "> **Nous devons nous rappeler que la recommandation n'est pas une prédiction.**<br>\n",
    "> S'appuyer sur des métriques ML pour déterminer la performance d'un système de recommandation n'est pas suffisant.<br>\n",
    "> Seul le retour des utilisateurs apporte des résultats valables et c'est pourquoi les tests A/B devraient toujours être priviligiés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1f9407-e2c0-41ff-b73d-08cd7fa61319",
   "metadata": {},
   "source": [
    "- Dans la mesure ou notre jeu de données **ne dispose pas de scores explicites**, il ne parrait pas souhaitable d'utiliser des métrique du type `MAE` ou `RMSE`.\n",
    "- Dans la mesure ou l'on **ne cherche pas particulièrement à obtenir un ordre précis**, il ne parrait pas souhaitable d'utiliser des métriques de ranking comme le `MAP@K` ou le `nDCCG`.\n",
    "- Nous pourrions donc nous tourner vers la `Precision@k`, le `Recall@K` et donc le `F1@k`, mais il est probable que ce ne soit pas très représentatif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43965753-74c8-4e03-88de-8db2f812a76e",
   "metadata": {},
   "source": [
    "#### Regardons la precision@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e38e5a-794d-400f-a450-0c9755623c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84041/84041 [00:27<00:00, 3048.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00013656251148963438"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.precision_at_k(model_bm25, train_sparse_user_item_bm25, valid_sparse_user_item_bm25, K=5, show_progress=True, num_threads=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e99bd-499e-423b-b1f2-2509df2a2397",
   "metadata": {},
   "source": [
    "> Le probleme c'est même si c'est l'une des métriques disponible les plus adaptée, elle reste peu adaptée à notre problème...<br>\n",
    "> Ici `Precision = (# of top k recommendations that are relevant)/(# of items that are recommended)`<br>\n",
    "> Mais malgré un nombre d'article assez large, on ne recommande que 5 articles et les utilisateurs ont un historique assez faible dans notre jeu de données. Donc les chances de recommander un article parmi 5 qui a effectivement été lu ensuite par l'utilisateur sont vraiment faible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01db85d-f7a2-4e7d-89bf-fd863cfb1786",
   "metadata": {},
   "source": [
    "### Construisons une métrique sur mesure\n",
    "\n",
    "Pour avoir une idée plus globale, nous pourrions comparer l'embedding moyen des articles lus APRÈS *(donc les actions contenues dans data_valid)* avec l'embedding moyen des article recommandés ET avec l'embedding moyen des articles lus AVANT *(donc les actions contenues dans le data_train)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae77db9-80c7-453a-8cba-03bd64c6da41",
   "metadata": {},
   "source": [
    "#### Récuperons la liste des articles lus par chaque utilisateur du validation set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7556fc02-8b07-44e5-a2c5-431a0fb6b96d",
   "metadata": {},
   "source": [
    "select = data_valid.groupby('user_id')['article_id'].apply(list).reset_index(name='article_ids')\n",
    "select = select.set_index('user_id')\n",
    "select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6a01343-bb8e-4428-b101-479ef563f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_lookup = pd.DataFrame(data_train.groupby('article_cat_code')['article_id'].apply(lambda x: list(x)[0])).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52c4fcc-cb56-4cc1-a007-7ed2b1514d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_ids</th>\n",
       "      <th>read_mean_embedding</th>\n",
       "      <th>pred_codes</th>\n",
       "      <th>pred_idx</th>\n",
       "      <th>pred_mean_embedding</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[36162]</td>\n",
       "      <td>[0.3944709, -0.9545699, -0.12643021, -0.031527...</td>\n",
       "      <td>[22509, 12972, 8237, 7534, 13106]</td>\n",
       "      <td>[284985, 158906, 96755, 87224, 160158]</td>\n",
       "      <td>[-0.1399826, -0.9593972, -0.44222125, 0.071453...</td>\n",
       "      <td>0.598711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[30760]</td>\n",
       "      <td>[-0.3254827, -0.96189374, -0.32057792, -0.7900...</td>\n",
       "      <td>[18554, 9648, 10394, 22265, 26768]</td>\n",
       "      <td>[233717, 111043, 119592, 283505, 348112]</td>\n",
       "      <td>[-0.50335515, -0.9651922, -0.1767746, -0.50258...</td>\n",
       "      <td>0.326945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[225010, 69353, 161872, 205845, 57748, 157815,...</td>\n",
       "      <td>[-0.024590481, -0.9645934, -0.06022447, -0.023...</td>\n",
       "      <td>[10394, 8217, 13141, 9556, 22427]</td>\n",
       "      <td>[119592, 96663, 160474, 108854, 284463]</td>\n",
       "      <td>[-0.43367648, -0.96880037, -0.12601939, -0.163...</td>\n",
       "      <td>0.718369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[202355]</td>\n",
       "      <td>[-0.09313608, -0.9619413, -0.22228149, 0.77629...</td>\n",
       "      <td>[18894, 18646, 18548, 19039, 22509]</td>\n",
       "      <td>[235689, 234269, 233688, 236444, 284985]</td>\n",
       "      <td>[-0.43889603, -0.96931684, -0.22122476, -0.144...</td>\n",
       "      <td>0.435389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[199474, 87223, 352979, 284470, 36162, 156279]</td>\n",
       "      <td>[-0.11400774, -0.96468645, -0.32728586, -0.201...</td>\n",
       "      <td>[7534, 18543, 7541, 7536, 7537]</td>\n",
       "      <td>[87224, 233658, 87236, 87231, 87232]</td>\n",
       "      <td>[-0.24903056, -0.9495894, -0.20430413, 0.59792...</td>\n",
       "      <td>0.604813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article_ids  \\\n",
       "user_id                                                      \n",
       "1                                                  [36162]   \n",
       "2                                                  [30760]   \n",
       "5        [225010, 69353, 161872, 205845, 57748, 157815,...   \n",
       "6                                                 [202355]   \n",
       "7           [199474, 87223, 352979, 284470, 36162, 156279]   \n",
       "\n",
       "                                       read_mean_embedding  \\\n",
       "user_id                                                      \n",
       "1        [0.3944709, -0.9545699, -0.12643021, -0.031527...   \n",
       "2        [-0.3254827, -0.96189374, -0.32057792, -0.7900...   \n",
       "5        [-0.024590481, -0.9645934, -0.06022447, -0.023...   \n",
       "6        [-0.09313608, -0.9619413, -0.22228149, 0.77629...   \n",
       "7        [-0.11400774, -0.96468645, -0.32728586, -0.201...   \n",
       "\n",
       "                                  pred_codes  \\\n",
       "user_id                                        \n",
       "1          [22509, 12972, 8237, 7534, 13106]   \n",
       "2         [18554, 9648, 10394, 22265, 26768]   \n",
       "5          [10394, 8217, 13141, 9556, 22427]   \n",
       "6        [18894, 18646, 18548, 19039, 22509]   \n",
       "7            [7534, 18543, 7541, 7536, 7537]   \n",
       "\n",
       "                                         pred_idx  \\\n",
       "user_id                                             \n",
       "1          [284985, 158906, 96755, 87224, 160158]   \n",
       "2        [233717, 111043, 119592, 283505, 348112]   \n",
       "5         [119592, 96663, 160474, 108854, 284463]   \n",
       "6        [235689, 234269, 233688, 236444, 284985]   \n",
       "7            [87224, 233658, 87236, 87231, 87232]   \n",
       "\n",
       "                                       pred_mean_embedding    cosine  \n",
       "user_id                                                               \n",
       "1        [-0.1399826, -0.9593972, -0.44222125, 0.071453...  0.598711  \n",
       "2        [-0.50335515, -0.9651922, -0.1767746, -0.50258...  0.326945  \n",
       "5        [-0.43367648, -0.96880037, -0.12601939, -0.163...  0.718369  \n",
       "6        [-0.43889603, -0.96931684, -0.22122476, -0.144...  0.435389  \n",
       "7        [-0.24903056, -0.9495894, -0.20430413, 0.59792...  0.604813  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(84041, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_cosine_similarity: 0.45\n"
     ]
    }
   ],
   "source": [
    "def get_mean_cosine_similarity(data_ref, pred_ref, verbose=1):\n",
    "\n",
    "    # --- for each user, get the ids of the articles he/she has read\n",
    "    select = data_ref.groupby('user_id')['article_id'].apply(list).reset_index(name='article_ids')\n",
    "\n",
    "    # --- for each user, compute the mean embedding vectors of the articles he/she has read\n",
    "    select['read_mean_embedding'] = select.apply(lambda x : article_embedding[np.array(x[1])].mean(axis=0), axis=1)\n",
    "    #select['size1'] = select['mean_embedding'].apply(lambda x : len(x))\n",
    "\n",
    "    # --- for each user, make recommendations\n",
    "    rec_size = 5\n",
    "    pred_codes, pred_scores = model_bm25.recommend(select.index, pred_ref[select.index], N=rec_size, filter_already_liked_items=True) \n",
    "    select['pred_codes'] = pred_codes.tolist()\n",
    "\n",
    "    # --- for each user, convert the article_cat_code to article_id\n",
    "    def lookup_articles(x):\n",
    "        return article_lookup['article_id'][x]\n",
    "\n",
    "    pred_idx = select['pred_codes'].apply(lambda x : list(map(lookup_articles,x)))\n",
    "    select['pred_idx'] = pred_idx.to_numpy().tolist()\n",
    "\n",
    "    # --- for each user, compute the mean embedding vectors of the recommended articles\n",
    "    select['pred_mean_embedding'] = select['pred_idx'].apply(lambda x : article_embedding[np.array(x)].mean(axis=0))\n",
    "\n",
    "    # --- for each user, compute the cosine similarity between the read_mean_embedding and the pred_mean_embedding\n",
    "    select['cosine'] = select.apply(lambda x: cosine_similarity(x['read_mean_embedding'].reshape(1, -1), x['pred_mean_embedding'].reshape(1, -1))[0][0], axis=1)\n",
    "\n",
    "    # --- reset the index column\n",
    "    select = select.set_index('user_id')\n",
    "\n",
    "    # --- Display sample\n",
    "    if verbose > 0:\n",
    "        display(select.head(), select.shape)\n",
    "\n",
    "    # --- Compute & return overall mean cosine similarity\n",
    "    return select.cosine.mean(), select\n",
    "\n",
    "MCS, MCS_df = get_mean_cosine_similarity(data_valid, valid_sparse_user_item_bm25, verbose=1)\n",
    "\n",
    "print(f\"mean_cosine_similarity: {MCS:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71604ca-a535-4330-80ba-380510348d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf49573-0114-4a5d-a231-02b1762709df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98579aa8-75d3-4683-aa08-f4b9396f79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8465203b-0c05-4f60-9607-2b78f6ab942d",
   "metadata": {},
   "source": [
    "# 1.2 Content Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756a876-7dab-46ae-93e3-31d2014d6715",
   "metadata": {},
   "source": [
    "articles_embeddings.pickle Pickle (Python 3) of a NumPy matrix containing the Article Content Embeddings (250-dimensional vectors), trained upon articles' text and metadata by the CHAMELEON's ACR module (see paper for details) for 364047 published articles.\n",
    "P.s. The full text of news articles could not be provided due to license restrictions, but those embeddings can be used by Neural Networks to represent their content. See this paper for a t-SNE visualization of these embeddings, colored by category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a55a8-3347-4847-b0da-e181838ab305",
   "metadata": {},
   "source": [
    "### Test: Calculons la cosine similarité entre deux vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a64e5b-5197-4a4b-8ac0-de89865d7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = article_embedding[162605]\n",
    "B = article_embedding[300884]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613ed2b-27ec-4f57-b32d-0731fd64f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00a714-0b1a-467a-8f73-f5bea259f891",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(A.reshape(1, -1),B.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee5380-5f3f-4d02-bf01-2f66ff4c669f",
   "metadata": {},
   "source": [
    "### Trouvons les articles lus par un utilisateur donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58772731-0d5a-4bc1-af62-aa6a52f7418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 20137\n",
    "history_size = 5\n",
    "\n",
    "def get_mean_vector(articles_idx, verbose=1):\n",
    "    \n",
    "    mean_vector = np.zeros(article_embedding[0].shape)\n",
    "    for article_id in articles_idx:\n",
    "        if verbose > 0:\n",
    "            print(article_id)\n",
    "        mean_vector += article_embedding[article_id]\n",
    "    mean_vector /= len(articles_idx)\n",
    "    return mean_vector\n",
    "\n",
    "last_articles_idx = data_train[data_train.user_id == user_id]['article_id'].iloc[-history_size:].values #.sort_values('click_timestamp')\n",
    "mean_vector = get_mean_vector(last_articles_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121247b4-6ce3-4463-864d-c57f2a0acfeb",
   "metadata": {},
   "source": [
    "### Calculons la similarité de ce vector avec les autres articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ffb0d-d5a9-4821-a020-26d74530fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = article_embedding\n",
    "#### ICI on drop les articles déjà lus par l'utilisateur\n",
    "B = mean_vector\n",
    "print(\"A:\", A.shape, \"B:\", B.shape, '\\n')\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine, cosine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7913df9-60a3-4721-bbfb-5ebe63d0b36b",
   "metadata": {},
   "source": [
    "### Recommandons 5 articles à l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a9825-0b89-45e3-ad6f-e3c3d562fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_articles(cosine, pred_size=5):\n",
    "    cos = pd.DataFrame(cosine, columns=['cosine_sim'])\n",
    "    selection = cos.sort_values('cosine_sim', ascending=False)[:pred_size]\n",
    "    selection.reset_index(inplace=True)\n",
    "    selection.rename(columns={'index':'article_id'}, inplace=True)\n",
    "    return selection\n",
    "\n",
    "pred = predict_articles(cosine, 5)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8c518-a529-4525-b41d-95d90eceda67",
   "metadata": {},
   "source": [
    "### Comparons avec les articles consultés par cet utilisateur dans le validation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a35220-61ce-49f0-b228-9a28a2dae237",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector_predicted = get_mean_vector(pred.article_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed69f1-33bc-4eec-b289-59593d8a8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewed = data_valid[data_valid.user_id == user_id]['article_id'].values\n",
    "mean_vector_viewed = get_mean_vector(viewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cda967-9481-43e3-bcaa-b8b1ee7fe043",
   "metadata": {},
   "source": [
    "#### Similarité entre les articles lus dans le `valid_set` et les articles prédis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722f7d1-44aa-46cf-b481-e2ca4bbbd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(A, B):\n",
    "    return np.dot(A,B)/(norm(A)*norm(B))\n",
    "\n",
    "cosine_similarity = get_cosine_similarity(mean_vector_predicted, mean_vector_viewed)\n",
    "print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39fb3c-3608-4e6a-9014-84f17ac57af7",
   "metadata": {},
   "source": [
    "#### Similarité entre les articles lus dans le `train_set` et les articles lus dans le `valid_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca73cf-904d-488f-803a-61cb905d0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = get_cosine_similarity(mean_vector, mean_vector_viewed)\n",
    "print(\"Cosine Similarity:\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf776be1-3841-45f8-b52f-5ca152b62a48",
   "metadata": {},
   "source": [
    "### RMSE entre la moyenne des embeddings des articles prédits et la moyenne des embeddings des articles lus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404c005-79d9-4933-b207-ea9d75a8b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_metrics.rmse(mean_vector_viewed, mean_vector_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a4477-3487-40cd-80af-7723ed846266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f4bf4-084a-41e6-b0d7-acb46c26fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_pred_viewed = []\n",
    "cosine_hist_viewed = []\n",
    "# rmse_pred_viewed = []\n",
    "mean_vectors_viewed = []\n",
    "mean_vectors_predicted = []\n",
    "\n",
    "for user_id in data_valid.user_id[:1000]:\n",
    "    # print(user_id)\n",
    "    last_articles_idx = data_train[data_train.user_id == user_id]['article_id'].iloc[-history_size:].values #.sort_values('click_timestamp')\n",
    "    mean_vector_hist = get_mean_vector(last_articles_idx, verbose=0)\n",
    "    \n",
    "    A = article_embedding\n",
    "    B = mean_vector_hist\n",
    "    cosine = np.dot(A,B)/(norm(A, axis=1)*norm(B))\n",
    "    \n",
    "    pred = predict_articles(cosine, 5)\n",
    "    mean_vector_pred = get_mean_vector(pred.article_id, verbose=0)\n",
    "    \n",
    "    viewed = data_valid[data_valid.user_id == user_id]['article_id'].values\n",
    "    mean_vector_viewed = get_mean_vector(viewed, verbose=0)\n",
    "    \n",
    "    cosine_similarity_pred_viewed = get_cosine_similarity(mean_vector_pred, mean_vector_viewed)\n",
    "    cosine_similarity_hist_viewed = get_cosine_similarity(mean_vector_hist, mean_vector_viewed)\n",
    "    # print(f\"Cosine Similarity :: pred/viewed={cosine_similarity_pred_viewed} | hist/viewed={cosine_similarity_hist_viewed}\")\n",
    "    #rmse = ml_metrics.rmse(mean_vector_viewed, mean_vector_predicted)\n",
    "    \n",
    "    cosine_pred_viewed.append(cosine_similarity_pred_viewed)\n",
    "    cosine_hist_viewed.append(cosine_similarity_hist_viewed)\n",
    "    #rmse_pred_viewed.append(rmse)\n",
    "    mean_vectors_viewed.append(mean_vector_viewed)\n",
    "    mean_vectors_predicted.append(mean_vector_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e03ce0-aa90-4de9-9747-8f9cbb90b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MEAN Cosine Similarity :: pred/viewed={np.mean(cosine_pred_viewed)} | hist/viewed={np.mean(cosine_hist_viewed)}\")\n",
    "#print(f\"RMSE :: pred/viewed={np.mean(rmse_pred_viewed)}\")\n",
    "print(f\"RMSE :: pred/viewed={ml_metrics.rmse(mean_vectors_viewed, mean_vectors_predicted)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0332eb5b-f44b-4b5f-b8f1-222d40ff5ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f688642-7cf9-4e81-95b4-81f31dc5444e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebb33a-5823-42bd-94df-afed13c52244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdda2c8-2b91-47a4-9a5a-880df5700b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ba360-88e2-43b0-bc7a-d1e901edf41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvP9",
   "language": "python",
   "name": "venvp9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
